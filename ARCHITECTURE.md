# Vexilla Architecture

> Deep dive into the design and decision-making behind Vexilla

## Table of Contents

1. [Overview](#overview)
2. [Architecture Diagram](#architecture-diagram)
3. [Core Components](#core-components)
4. [Evaluation Strategies](#evaluation-strategies)
5. [Flag Filtering System](#flag-filtering-system)
6. [Data Flow](#data-flow)
7. [Performance Characteristics](#performance-characteristics)
8. [Deterministic Rollout Pattern](#deterministic-rollout-pattern)
9. [Design Decisions](#design-decisions)
10. [Recent Enhancements](#recent-enhancements)

---

## Overview

Vexilla is a high-performance caching layer for [Flagr](https://github.com/openflagr/flagr) that intelligently routes feature flag evaluations between local (cached) and remote (Flagr API) evaluation based on the flag's configuration.

### Key Insight

Most feature flags are **deterministic** - they always produce the same result for the same input. These don't need Flagr's stateful bucketing and can be evaluated locally in <1ms with zero HTTP requests.

Only flags with **percentage-based rollouts** or **A/B testing** require Flagr's consistent hashing for sticky user assignments.

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Your Application                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  HTTP API  â”‚  â”‚  Services  â”‚  â”‚   Workers  â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚        â”‚               â”‚               â”‚                            â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                        â”‚                                            â”‚
â”‚                  HTTP Middleware (optional)                         â”‚
â”‚                        â”‚                                            â”‚
â”‚                        â–¼                                            â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚              â”‚    Cache (pkg)      â”‚                                â”‚
â”‚              â”‚  - Orchestration    â”‚                                â”‚
â”‚              â”‚  - Routing Logic    â”‚                                â”‚
â”‚              â”‚  - Circuit Breaker  â”‚                                â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                â”‚                 â”‚
        â–¼                â–¼                â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Storage     â”‚  â”‚  Evaluator   â”‚  â”‚  Flagr       â”‚  â”‚  Servers     â”‚
â”‚  (Memory/    â”‚  â”‚  (Local)     â”‚  â”‚  Client      â”‚  â”‚  (Admin/     â”‚
â”‚   Disk)      â”‚  â”‚              â”‚  â”‚  (HTTP)      â”‚  â”‚   Webhook)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚                 â”‚
                                            â–¼                 â–¼
                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â”‚  Flagr Server â”‚  â”‚  Admin API   â”‚
                                   â”‚   (HTTP API)  â”‚  â”‚  Webhook API â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Core Components

### 1. Cache (`pkg/cache/cache.go`)

The main orchestrator that coordinates all components.

```go
type Cache struct {
    // Dependencies (injected)
    flagrClient flagr.Client
    storage     storage.Storage
    evaluator   evaluator.Evaluator

    // Configuration
    config Config

    // State management
    ctx    context.Context
    cancel context.CancelFunc
    wg     sync.WaitGroup

    // Circuit breaker state
    mu               sync.RWMutex
    lastRefresh      time.Time
    consecutiveFails int
    circuitOpen      bool
}
```

**Responsibilities:**
- Lifecycle management (Start/Stop)
- Coordination between components
- Evaluation routing (local vs remote)
- Circuit breaker management
- Background refresh orchestration

**Key Methods:**
- `Start(ctx)` - Initializes cache, loads flags, starts background processes
- `Evaluate()` - Main evaluation entry point with routing logic
- `EvaluateBool/String/Int()` - Convenience methods
- `refreshFlags()` - Background refresh with circuit breaker
- `GetMetrics()` - Returns comprehensive metrics

### 2. Storage Layer (`pkg/storage/`)

Provides pluggable storage implementations.

#### Memory Storage (`memory.go`)

High-performance in-memory cache using [Ristretto](https://github.com/dgraph-io/ristretto).

**Why Ristretto?**
- Concurrent: Lock-free reads
- Smart eviction: TinyLFU admission policy
- High throughput: Millions of ops/sec
- Built-in metrics
- TTL support

```go
type MemoryStorage struct {
    cache   *ristretto.Cache
    config  Config
    metrics Metrics
}
```

**Configuration:**
```go
Config{
    MaxCost:     1 << 30,    // 1GB
    NumCounters: 1e7,        // 10M counters
    BufferItems: 64,         // Buffer size
    DefaultTTL:  5 * time.Minute,
}
```

#### Disk Storage (`disk.go`)

Persistent storage for warm cache on restart.

```go
type DiskStorage struct {
    dir     string
    metrics Metrics
    mu      sync.RWMutex
}
```

**Features:**
- JSON-based storage
- Snapshot support
- Atomic operations
- Thread-safe

**Use Cases:**
- Fast startup (warm cache)
- Survives restarts
- Last-known-good fallback

### 3. Evaluator (`pkg/evaluator/evaluator.go`)

Evaluates flags locally using [expr-lang/expr](https://github.com/expr-lang/expr).

```go
type LocalEvaluator struct {
    programCache map[string]*vm.Program
}
```

**Supported Operators:**
- `EQ`, `NEQ` - Equality
- `IN`, `NOTIN` - List membership
- `LT`, `LTE`, `GT`, `GTE` - Numeric comparison
- `MATCHES` - Regex matching
- `CONTAINS` - String contains

**Evaluation Process:**
1. Check if flag is enabled
2. Iterate segments by rank
3. Evaluate constraints (AND logic)
4. Return matching variant

**Strategy Determination:**
```go
func (e *LocalEvaluator) CanEvaluateLocally(flag domain.Flag) bool {
    strategy := flag.DetermineStrategy()
    return strategy == domain.StrategyLocal
}
```

### 4. Flagr Client (`pkg/flagr/http.go`)

HTTP client for Flagr API with retry logic.

```go
type HTTPClient struct {
    endpoint   string
    apiKey     string
    httpClient *http.Client
    maxRetries int
}
```

**Features:**
- Automatic retries (exponential backoff)
- Timeout handling
- Authentication support
- Error wrapping

**Endpoints Used:**
- `GET /api/v1/flags` - Fetch all flags
- `GET /api/v1/flags/:id` - Fetch single flag
- `POST /api/v1/evaluation` - Remote evaluation
- `GET /api/v1/health` - Health check

### 5. Circuit Breaker (`pkg/circuit/breaker.go`)

Prevents cascade failures when Flagr is down.

```go
type Breaker struct {
    state           State  // Closed, Open, HalfOpen
    failures        int
    maxFailures     int
    timeout         time.Duration
    halfOpenTimeout time.Duration
}
```

**State Machine:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  failures >= max   â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚ CLOSED  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ OPEN â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”¬â”€â”€â”˜
     â”‚                              â”‚
     â”‚ success                      â”‚ timeout
     â”‚                              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”˜
                        â”‚    â”‚
                   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                   â”‚  HALF-OPEN   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**States:**
- `Closed`: Normal operation
- `Open`: Blocking requests (after threshold failures)
- `Half-Open`: Testing recovery

**Configuration:**
```go
Config{
    MaxFailures:     3,
    Timeout:         30 * time.Second,
    HalfOpenTimeout: 10 * time.Second,
}
```

### 6. Telemetry (`pkg/telemetry/`)

OpenTelemetry integration for observability.

```go
type OTelProvider struct {
    tracer trace.Tracer
    meter  metric.Meter
    
    // Metrics
    cacheHits       metric.Int64Counter
    cacheMisses     metric.Int64Counter
    evaluations     metric.Int64Counter
    refreshDuration metric.Float64Histogram
}
```

**Metrics Exported:**
- `vexilla.cache.hits` - Cache hit counter
- `vexilla.cache.misses` - Cache miss counter
- `vexilla.evaluations` - Total evaluations (with strategy label)
- `vexilla.refresh.duration` - Refresh latency histogram
- `vexilla.refresh.success/failure` - Refresh success/failure counters
- `vexilla.circuit.state` - Circuit breaker state gauge

**Traces:**
- All operations instrumented
- Rich contextual attributes
- Error recording

### 7. Servers (`pkg/server/`)

#### Webhook Server (`webhook.go`)

Receives real-time updates from Flagr.

```go
type WebhookServer struct {
    cache  CacheInterface
    port   int
    secret string
}
```

**Events Handled:**
- `flag.updated` - Invalidates and refreshes
- `flag.deleted` - Invalidates flag

**Security:**
- HMAC-SHA256 signature verification
- Configurable secret

#### Admin API (`admin.go`)

Management interface for operations.

**Endpoints:**
- `GET /health` - Health check
- `GET /admin/stats` - Cache metrics
- `POST /admin/invalidate` - Invalidate specific flag
- `POST /admin/invalidate-all` - Clear cache
- `POST /admin/refresh` - Force refresh

#### Middleware (`middleware.go`)

HTTP middleware for automatic request context injection.

```go
type Middleware struct {
    cache CacheInterface
}
```

**Features:**
- Extracts user context from HTTP headers
- Builds evaluation context automatically from request data
- Injects cache and context into request
- Drop-in integration with standard `http.Handler`

**Usage Example:**
```go
// Wrap any HTTP handler
handler := client.HTTPMiddleware(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
    userID := r.Header.Get("X-User-ID")
    evalCtx := vexilla.NewContext(userID)

    if client.Bool(r.Context(), "new-feature", evalCtx) {
        // Feature enabled
    }
}))

http.ListenAndServe(":8080", handler)
```

**Benefits:**
- Eliminates boilerplate context extraction
- Consistent context building across endpoints
- Seamless integration with existing HTTP routers

---

## Evaluation Strategies

### Decision Tree

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Flag Evaluation Request            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Load flag from storage              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Determine evaluation strategy       â”‚
â”‚  CanEvaluateLocally(flag)?           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
       â”‚               â”‚
     YES              NO
       â”‚               â”‚
       â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LOCAL     â”‚  â”‚     FLAGR       â”‚
â”‚  EVALUATION â”‚  â”‚   EVALUATION    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚
       â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Evaluate   â”‚  â”‚  HTTP POST              â”‚
â”‚  constraintsâ”‚  â”‚  /api/v1/evaluation     â”‚
â”‚  with expr  â”‚  â”‚                         â”‚
â”‚             â”‚  â”‚  Flagr performs:        â”‚
â”‚  <1ms       â”‚  â”‚  â€¢ Consistent hashing   â”‚
â”‚  0 HTTP     â”‚  â”‚  â€¢ Bucket assignment    â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â€¢ Variant distribution â”‚
      â”‚          â”‚                         â”‚
      â”‚          â”‚  50-200ms               â”‚
      â”‚          â”‚  1 HTTP request         â”‚
      â”‚          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                 â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Return    â”‚
        â”‚   Result    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Strategy Determination Logic

```go
func (f *Flag) DetermineStrategy() EvaluationStrategy {
    if !f.Enabled {
        return StrategyLocal // Disabled = always local
    }

    if len(f.Segments) == 0 {
        return StrategyLocal // No segments = local
    }

    for _, segment := range f.Segments {
        // Partial rollout â†’ remote
        if segment.RolloutPercent > 0 && segment.RolloutPercent < 100 {
            return StrategyRemote
        }

        // Multiple distributions (A/B) â†’ remote
        if len(segment.Distributions) > 1 {
            return StrategyRemote
        }

        // Single distribution < 100% â†’ remote
        if len(segment.Distributions) == 1 {
            if segment.Distributions[0].Percent < 100 {
                return StrategyRemote
            }
        }
    }

    return StrategyLocal // 100% deterministic
}
```

---

## Flag Filtering System

### Overview

The filtering system allows selective caching of flags to optimize memory usage and cache efficiency. This is especially valuable in microservice architectures where each service only needs a subset of flags.

### Filter Configuration

```go
type FilterConfig struct {
    // OnlyEnabled: Cache only enabled flags
    OnlyEnabled bool

    // ServiceName: Current service identifier
    ServiceName string

    // RequireServiceTag: Only cache flags tagged with ServiceName
    RequireServiceTag bool

    // AdditionalTags: Additional tag filtering
    AdditionalTags []string

    // TagMatchMode: "any" or "all"
    TagMatchMode string
}
```

### Filtering Logic

```go
func (f FilterConfig) ShouldCacheFlag(flag FlagMetadata) bool {
    // Rule 1: OnlyEnabled filter
    if f.OnlyEnabled && !flag.Enabled {
        return false
    }

    // Rule 2: Service tag filter
    if f.RequireServiceTag {
        if !hasTag(flag.Tags, f.ServiceName) {
            return false
        }
    }

    // Rule 3: Additional tags filter
    if len(f.AdditionalTags) > 0 {
        if !matchesTags(flag.Tags, f.AdditionalTags, f.TagMatchMode) {
            return false
        }
    }

    return true
}
```

### Memory Savings Calculation

```go
func (f FilterConfig) EstimateMemorySavings(totalFlags, filteredFlags int) MemorySavings {
    savedFlags := totalFlags - filteredFlags
    percentSaved := float64(savedFlags) / float64(totalFlags) * 100
    
    // Rough estimate: 1KB per flag
    const bytesPerFlag = 1024
    savedBytes := int64(savedFlags * bytesPerFlag)
    
    return MemorySavings{
        TotalFlags:      totalFlags,
        CachedFlags:     filteredFlags,
        FilteredFlags:   savedFlags,
        PercentFiltered: percentSaved,
        BytesSaved:      savedBytes,
    }
}
```

### Use Cases

**1. Microservice Architecture:**
```go
// Each service caches only its flags
WithServiceTag("user-service", true)
// 1000 total flags â†’ 50 for user-service = 95% memory saving
```

**2. Environment Separation:**
```go
// Only cache production flags
WithAdditionalTags([]string{"production"}, "any")
// Avoids caching staging/dev flags in production
```

**3. Resource Optimization:**
```go
// Only enabled flags for active service
WithOnlyEnabled(true)
WithServiceTag("payment-service", true)
// Maximum memory efficiency
```

---

## Data Flow

### Initial Load

```
Application Start
    â”‚
    â–¼
Cache.Start(ctx)
    â”‚
    â”œâ”€> Load from disk (if DiskStorage configured)
    â”‚   â””â”€> Warm cache with persisted flags
    â”‚
    â”œâ”€> HTTP GET /api/v1/flags (fetch all IDs)
    â”‚   â””â”€> For each flag ID:
    â”‚       â””â”€> HTTP GET /api/v1/flags/:id (detailed)
    â”‚
    â”œâ”€> Apply filtering (if configured)
    â”‚   â””â”€> FilterConfig.ShouldCacheFlag()
    â”‚       â”œâ”€> OnlyEnabled filter
    â”‚       â”œâ”€> ServiceTag filter
    â”‚       â””â”€> AdditionalTags filter
    â”‚
    â”œâ”€> Store in Ristretto
    â”‚   â””â”€> storage.Set(key, flag, ttl)
    â”‚
    â”œâ”€> Start background refresh goroutine
    â”‚
    â”œâ”€> Start webhook server (if enabled)
    â”‚   â””â”€> Listen on configured port
    â”‚       â””â”€> Handle flag.updated and flag.deleted events
    â”‚
    â””â”€> Start admin API (if enabled)
        â””â”€> Listen on configured port
            â””â”€> Expose management endpoints
```

### Background Refresh

```
Every N minutes (default: 5)
    â”‚
    â–¼
Check circuit breaker
    â”‚
    â”œâ”€> Open? Skip refresh, return error
    â”‚
    â””â”€> Closed/HalfOpen? Continue
        â”‚
        â–¼
    HTTP GET /api/v1/flags â†’ for each: GET /api/v1/flags/:id
        â”‚
        â”œâ”€> Success
        â”‚   â”œâ”€> Apply filtering
        â”‚   â”œâ”€> Update cache (storage.Set)
        â”‚   â”œâ”€> Reset circuit breaker
        â”‚   â”œâ”€> Save to disk (if DiskStorage)
        â”‚   â””â”€> Update lastRefresh timestamp
        â”‚
        â””â”€> Failure
            â”œâ”€> Increment consecutiveFails
            â”œâ”€> If fails >= threshold: Open circuit
            â””â”€> Return error
```

### Webhook Flow

```
Flagr UI: Flag Updated
    â”‚
    â–¼
POST /webhook
{
  "event": "flag.updated",
  "flag_keys": ["feature_x"],
  "timestamp": "2025-01-15T10:30:00Z"
}
    â”‚
    â–¼
Verify HMAC signature (if secret configured)
    â”‚
    â”œâ”€> Invalid? Return 401
    â”‚
    â””â”€> Valid? Continue
        â”‚
        â–¼
    Parse payload
        â”‚
        â–¼
    Handle event
        â”‚
        â”œâ”€> "flag.updated"
        â”‚   â”œâ”€> For each flag_key:
        â”‚   â”‚   â””â”€> storage.Delete(flag_key)
        â”‚   â””â”€> Trigger immediate refresh
        â”‚
        â””â”€> "flag.deleted"
            â””â”€> For each flag_key:
                â””â”€> storage.Delete(flag_key)
    â”‚
    â–¼
Response 200 OK
```

### Evaluation Flow

```
cache.Evaluate(ctx, flagKey, evalCtx)
    â”‚
    â–¼
storage.Get(flagKey)
    â”‚
    â”œâ”€> Found
    â”‚   â”‚
    â”‚   â–¼
    â”‚   evaluator.CanEvaluateLocally(flag)?
    â”‚   â”‚
    â”‚   â”œâ”€> Yes (Local Strategy)
    â”‚   â”‚   â”‚
    â”‚   â”‚   â–¼
    â”‚   â”‚   evaluator.Evaluate(flag, evalCtx)
    â”‚   â”‚   â”‚
    â”‚   â”‚   â”œâ”€> Check flag.Enabled
    â”‚   â”‚   â”œâ”€> Iterate segments by rank
    â”‚   â”‚   â”œâ”€> Evaluate constraints (AND logic)
    â”‚   â”‚   â”‚   â””â”€> expr engine for operators
    â”‚   â”‚   â””â”€> Return matching variant
    â”‚   â”‚       â”‚
    â”‚   â”‚       â””â”€> <1ms, 0 HTTP requests
    â”‚   â”‚
    â”‚   â””â”€> No (Remote Strategy)
    â”‚       â”‚
    â”‚       â–¼
    â”‚       Check circuit breaker
    â”‚       â”‚
    â”‚       â”œâ”€> Open? Return error
    â”‚       â”‚
    â”‚       â””â”€> Closed? Continue
    â”‚           â”‚
    â”‚           â–¼
    â”‚           flagrClient.EvaluateFlag(flagKey, evalCtx)
    â”‚           â”‚
    â”‚           â””â”€> POST /api/v1/evaluation
    â”‚               â”‚
    â”‚               â””â”€> 50-200ms, 1 HTTP request
    â”‚
    â””â”€> Not Found
        â”‚
        â–¼
        Refresh all flags from Flagr
        â”‚
        â””â”€> Retry evaluation OR apply fallback strategy
```

---

## Performance Characteristics

### Latency Comparison

**Real benchmark data (AMD Ryzen 5 5600G, 12 cores, Windows):**

| Operation | Latency (ns) | Latency (Î¼s) | HTTP Requests | Notes |
|-----------|--------------|--------------|---------------|-------|
| Local evaluation (simple) | **335.0** | **0.335** | 0 | 9.4M ops/sec |
| Local evaluation (constraints) | **582.0** | **0.582** | 0 | 5.3M ops/sec |
| Local evaluation (multiple segments) | **525.7** | **0.526** | 0 | 6.0M ops/sec |
| Local evaluation (complex) | **625.2** | **0.625** | 0 | 5.9M ops/sec |
| Cache hit (Ristretto) | **364.9** | **0.365** | 0 | 10.4M ops/sec |
| Concurrent evaluations | **85.85** | **0.086** | 0 | 11.6M ops/sec |
| Deterministic rollout | **735.7** | **0.736** | 0 | 5.5M ops/sec |
| Client API Bool() | **73.05** | **0.073** | 0 | 13.7M ops/sec |
| Client API Evaluate() | **71.48** | **0.071** | 0 | 14.0M ops/sec |
| Storage get | **354.9** | **0.355** | 0 | 15.9M ops/sec |
| Storage set | **2742** | **2.742** | 0 | 1.2M ops/sec |
| Remote evaluation (dynamic) | 50-200ms | 50,000-200,000 | 1 | Full Flagr evaluation |

### Throughput

**Real benchmark results (AMD Ryzen 5 5600G, 12 cores, Windows):**

```
Local Evaluation Performance:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Benchmark                  â”‚  ns/op   â”‚   Î¼s/op    â”‚ B/op   â”‚ allocs/opâ”‚  ops/sec     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Simple                     â”‚  335.0   â”‚   0.335    â”‚  448   â”‚    6     â”‚  9,378,348   â”‚
â”‚ WithConstraints            â”‚  582.0   â”‚   0.582    â”‚  469   â”‚   10     â”‚  5,320,131   â”‚
â”‚ MultipleSegments           â”‚  525.7   â”‚   0.526    â”‚  656   â”‚    8     â”‚  6,023,908   â”‚
â”‚ ComplexConstraints         â”‚  625.2   â”‚   0.625    â”‚  461   â”‚   10     â”‚  5,936,235   â”‚
â”‚ DeterministicRollout       â”‚  735.7   â”‚   0.736    â”‚  887   â”‚   10     â”‚  5,519,619   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

High-Performance Operations:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Benchmark                  â”‚  ns/op   â”‚   Î¼s/op    â”‚ B/op   â”‚ allocs/opâ”‚  ops/sec     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ConcurrentEvaluations      â”‚   85.85  â”‚   0.086    â”‚  464   â”‚    7     â”‚ 37,708,219   â”‚
â”‚ ClientAPI_Bool             â”‚   73.05  â”‚   0.073    â”‚   23   â”‚    1     â”‚ 47,826,802   â”‚
â”‚ ClientAPI_Evaluate         â”‚   71.48  â”‚   0.071    â”‚   23   â”‚    1     â”‚ 50,354,086   â”‚
â”‚ CacheHit                   â”‚  364.9   â”‚   0.365    â”‚  447   â”‚    6     â”‚ 10,438,270   â”‚
â”‚ StorageGet                 â”‚  354.9   â”‚   0.355    â”‚  197   â”‚    3     â”‚ 15,949,852   â”‚
â”‚ StorageSet                 â”‚ 2742.0   â”‚   2.742    â”‚  743   â”‚    7     â”‚  1,248,972   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Throughput Summary:
- Simple evaluation:        9.4M ops/sec  âš¡âš¡âš¡
- Concurrent (12 cores):   37.7M ops/sec  âš¡âš¡âš¡âš¡âš¡
- Client API Bool():       47.8M ops/sec  ğŸš€
- Client API Evaluate():   50.4M ops/sec  ğŸš€ğŸš€
- Cache hit:               10.4M ops/sec  âš¡âš¡

Performance vs Remote Evaluation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scenario                â”‚ Vexilla    â”‚ Flagr      â”‚ Speedup    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Simple flag             â”‚  335 ns    â”‚ ~150,000 Î¼sâ”‚  447,761x  â”‚
â”‚ Complex flag            â”‚  625 ns    â”‚ ~200,000 Î¼sâ”‚  320,000x  â”‚
â”‚ Deterministic rollout   â”‚  736 ns    â”‚ ~150,000 Î¼sâ”‚  203,804x  â”‚
â”‚ Client API (fastest)    â”‚   71 ns    â”‚ ~150,000 Î¼sâ”‚2,112,676x  â”‚
â”‚ 1 million evaluations   â”‚  0.335 sec â”‚  41.7 hoursâ”‚  448,358x  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Scaling Analysis (Large Cache):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Benchmark                  â”‚  ns/op   â”‚  ops/sec     â”‚  Impact      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LargeScaleCache_1000       â”‚  471.2   â”‚  7,264,365   â”‚  Baseline    â”‚
â”‚ LargeScaleCache_10000      â”‚  583.0   â”‚  6,115,700   â”‚  -16% slower â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Impact: Only 16% slower with 10x more flags - Excellent scaling! âœ…
```

### Memory Usage

**Real benchmark data (AMD Ryzen 5 5600G, Windows):**

**Per Evaluation:**
- Simple evaluation: **448 bytes**, 6 allocations
- With constraints: **469 bytes**, 10 allocations
- Multiple segments: **656 bytes**, 8 allocations
- Complex constraints: **461 bytes**, 10 allocations
- Concurrent evaluations: **464 bytes**, 7 allocations
- Deterministic rollout: **887 bytes**, 10 allocations
- Client API: **23 bytes**, 1 allocation (ultra-efficient!)

**Storage Operations:**
- Get operation: **197 bytes**, 3 allocations
- Set operation: **743 bytes**, 7 allocations

**Cache Operations:**
- Cache hit: **447 bytes**, 6 allocations
- Constraint matching: **285 bytes**, 8 allocations
- Memory allocation test: **471 bytes**, 8 allocations

**Per Flag (estimated):**
- Flag struct: ~500 bytes
- Metadata: ~100 bytes
- Ristretto overhead: ~200 bytes
- **Total: ~800 bytes per flag**

**Scaling:**
- 100 flags: ~80 KB
- 1,000 flags: ~800 KB
- 10,000 flags: ~8 MB
- 100,000 flags: ~80 MB

**With Filtering (Example):**
- 10,000 total flags
- Service-specific: 500 flags (95% filtered)
- Memory used: ~400 KB vs 8 MB
- **Savings: ~7.6 MB (95% reduction)**

### Ristretto Performance

**Real benchmark data (AMD Ryzen 5 5600G, 12 cores):**

```
Storage Operations per second:
- Set:  1,248,972 ops/sec (2,742 ns/op, 743 B/op)
- Get: 15,949,852 ops/sec (354.9 ns/op, 197 B/op)
- Cache hit: 10,438,270 ops/sec (364.9 ns/op, 447 B/op)

Concurrent Performance:
- 12-core throughput: 37.7M ops/sec
- Parallel efficiency: ~95% (3.1M per core)
- Excellent scaling âœ…

Memory efficiency:
- Admission rate: ~95% (TinyLFU)
- Eviction accuracy: Very high
- Minimal allocations: 448B per eval
- Client API: Only 23B per call!
```

### Key Performance Takeaways

âœ… **Sub-microsecond evaluations**: All local evaluations < 1 Î¼s (335-736 ns)
âœ… **Exceptional concurrency**: 37.7M ops/sec concurrent evaluations
âœ… **Ultra-fast API**: Client API calls at 71-73 ns (50M+ ops/sec)
âœ… **Excellent scaling**: 10,000 flags only 16% slower than 1,000 flags
âœ… **Memory efficient**: 448 bytes per evaluation, Client API only 23 bytes
âœ… **Production-ready**: All metrics exceed targets by 100-500x
âœ… **Massive speedup**: 200,000-2,000,000x faster than Flagr API calls

ğŸ“Š [Full benchmark results and analysis â†’](../benchmarks/results/REAL_RESULTS.md)

---

## Deterministic Rollout Pattern

### Overview

Vexilla enables a powerful pattern for **deterministic rollouts** that eliminates the need for random percentage-based evaluations, enabling 100% local evaluation with zero HTTP dependencies.

### Problem with Traditional Rollouts

Traditional percentage-based rollouts have several drawbacks:
- **Non-deterministic**: Random evaluation means results can change between calls
- **HTTP-dependent**: Requires Flagr API calls for consistent hashing
- **Hard to debug**: Difficult to reproduce user-specific behavior
- **Network latency**: Adds 50-200ms per evaluation

### Solution: Pre-computed Buckets

Instead of relying on Flagr's random rollout percentages, applications can pre-compute a **deterministic bucket** from user identifiers and send it as a simple numeric attribute.

### Architecture

```
User Identifier (CPF, UserID, etc.)
    â”‚
    â–¼
Application (pre-processing)
    â”‚
    â”œâ”€> Extract/Hash identifier
    â”‚   â””â”€> Generate bucket: 0-99
    â”‚
    â–¼
Vexilla.Evaluate(ctx, flag, {bucket: 42})
    â”‚
    â–¼
Local Evaluation (no HTTP)
    â”‚
    â”œâ”€> Check: bucket >= 0 AND bucket <= 69?
    â”‚   â””â”€> Match: Variant A
    â”‚
    â””â”€> Else: Default variant
```

### Example: CPF-based Bucketing

```go
// Pre-processing: Extract bucket from CPF
func CPFBucket(cpf string) int {
    clean := strings.NewReplacer(".", "", "-", "").Replace(cpf)
    if len(clean) < 7 {
        return -1
    }

    // Use digits 6-7 to create bucket 00-99
    bucket, err := strconv.Atoi(clean[5:7])
    if err != nil {
        return -1
    }

    return bucket
}

// Usage
attrs := vexilla.Attributes{
    "cpf_bucket": CPFBucket("123.456.789-09"),
}

enabled := client.Bool(ctx, "new-feature", attrs)
```

### Flagr Configuration

**Segment: audience_a (70% rollout)**

| Field      | Operator | Value |
|------------|----------|-------|
| cpf_bucket | >=       | 0     |
| cpf_bucket | <=       | 69    |

**Segment: default (30% rollout)**
- No constraints (matches all others)

### Benefits

âœ… **Deterministic**: Same input always produces same result
âœ… **100% Local**: No HTTP calls to Flagr needed
âœ… **Sub-millisecond**: <1ms evaluation latency
âœ… **Reproducible**: Easy to debug user-specific behavior
âœ… **Offline-capable**: Works without network connectivity
âœ… **Cacheable**: Fully compatible with Vexilla's caching layer

### Performance Comparison

| Approach | Latency | HTTP Calls | Deterministic | Throughput |
|----------|---------|------------|---------------|------------|
| Flagr % rollout | 50-200ms | 1 per eval | âŒ Random | ~2K ops/sec |
| Deterministic bucket | **735 ns** | 0 | âœ… Stable | **5.5M ops/sec** |

**Real benchmark data:**
- Speedup: **203,804x faster** than Flagr API
- Throughput: **2,750x higher** than remote evaluation
- Zero network overhead âœ…

### Use Cases

This pattern is ideal for:
- **Critical features**: Where latency matters
- **Edge computing**: Limited connectivity environments
- **Mobile apps**: Reduce battery drain from network calls
- **Compliance**: Reproducible audit trails
- **A/B testing**: Stable user assignments without sticky sessions

### Applicable Identifiers

Any stable identifier can be used:
- User ID (hash % 100)
- Account ID
- Document numbers (CPF, SSN, etc.)
- Email hash
- Device ID
- Session ID (for short-term experiments)

---

## Design Decisions

### 1. Why Ristretto over sync.Map?

| Feature | Ristretto | sync.Map |
|---------|-----------|----------|
| Eviction | âœ… Smart (TinyLFU) | âŒ None (unbounded) |
| Metrics | âœ… Built-in | âŒ Manual tracking |
| Memory bounds | âœ… Configurable | âŒ Unbounded growth |
| Throughput | âš¡ 10-30M ops/sec | ğŸ¢ Lower |
| TTL support | âœ… Native | âŒ Manual expiry |
| Admission policy | âœ… TinyLFU (intelligent) | âŒ N/A |

**Verdict:** Ristretto provides production-grade caching with bounded memory, high performance, and intelligent eviction.

### 2. Why expr-lang/expr?

**Alternatives Considered:**
- `text/template` - Too limited
- `github.com/antonmedv/expr` âœ… **Chosen**
- `github.com/robertkrimen/otto` - Full JS engine (overkill)
- Custom parser - Too much maintenance

**Why expr?**
- âœ… Safe sandbox (no code execution)
- âœ… Rich expression syntax
- âœ… Good performance (~1Î¼s per eval)
- âœ… Easy integration
- âœ… Type-safe evaluation
- âœ… Regex support

### 3. Why Circuit Breaker?

**Problem:** When Flagr is down, applications shouldn't retry indefinitely.

**Circuit Breaker Benefits:**
- Prevents cascade failures
- Fails fast (no waiting for timeouts)
- Automatic recovery testing (half-open)
- Configurable thresholds

**Trade-offs:**
- Adds complexity
- Requires tuning (max failures, timeout)
- May block valid requests during recovery

**Verdict:** Essential for production resilience. Cost is worth the protection.

### 4. Why Disk Persistence?

**Benefits:**
- Fast startup (warm cache from disk)
- Survives restarts (last-known-good state)
- Graceful degradation if Flagr is down

**Trade-offs:**
- Disk I/O overhead (mitigated: async writes)
- Stale data risk (mitigated: TTL + refresh)
- Disk space usage (minimal: ~1KB per flag)

**Verdict:** Optional but recommended. Provides excellent startup performance.

### 5. Why Flag Filtering?

**Problem:** In microservice architectures, each service doesn't need all 10,000+ flags.

**Filtering Benefits:**
- âœ… Reduced memory footprint (50-95% savings)
- âœ… Faster cache operations (smaller dataset)
- âœ… Better cache hit ratios
- âœ… Lower refresh overhead

**Example Impact:**
```
Without filtering:
- 10,000 flags Ã— 1KB = 10 MB memory
- Refresh time: ~30 seconds

With filtering (5% relevant):
- 500 flags Ã— 1KB = 500 KB memory (95% saving)
- Refresh time: ~1.5 seconds (95% faster)
```

**Verdict:** Critical for microservice deployments. Dramatically improves efficiency.

### 6. Why Separate Storage Interface?

**Benefits:**
- Testability (mock storage)
- Flexibility (swap implementations)
- Future-proofing (Redis, etc.)

**Implementations:**
- `MemoryStorage` - Production (Ristretto)
- `DiskStorage` - Persistence option
- `MockStorage` - Testing

**Verdict:** Clean separation of concerns. Easy to extend.

---

## Scalability

### Horizontal Scaling

```
Each instance maintains its own cache:

Instance 1: [Ristretto Cache] â”€â”
Instance 2: [Ristretto Cache] â”€â”¼â”€> Flagr Server
Instance 3: [Ristretto Cache] â”€â”¤
Instance N: [Ristretto Cache] â”€â”˜
```

**Pros:**
- âœ… No coordination needed
- âœ… Linear scalability
- âœ… Simple deployment
- âœ… No single point of failure

**Cons:**
- âš ï¸ Cache inconsistency during refresh window (acceptable)
- âš ï¸ Each instance refreshes independently

**Mitigation:**
- Webhook support for real-time updates
- Short refresh intervals (1-5 minutes)
- Staggered refresh (add jitter)

### Vertical Scaling

Ristretto can scale to very large datasets:

```
Memory capacity:
- 1K flags:   ~1 MB
- 10K flags:  ~10 MB
- 100K flags: ~100 MB
- 1M flags:   ~1 GB
```

**Configuration for Large Deployments:**
```go
Config{
    MaxCost:     10 << 30,  // 10GB
    NumCounters: 1e8,       // 100M counters
    BufferItems: 256,       // Larger buffer
}
```

### Performance at Scale

**10K flags, 10K req/s:**
- Local evaluations: ~9,500/s (95% local)
- Remote evaluations: ~500/s (5% remote)
- Flagr load: 500 req/s (vs 10K without Vexilla)
- **95% load reduction on Flagr**

---

## Recent Enhancements

### âœ… Implemented Features (Latest Version)

1. **âœ… Webhook Invalidation**
   - Real-time flag updates from Flagr
   - HMAC-SHA256 signature verification
   - Event-driven cache invalidation
   - Sub-second update propagation

   ```go
   vexilla.WithWebhookInvalidation(vexilla.WebhookConfig{
       Port:   18001,
       Secret: "shared-secret",
   })
   ```

2. **âœ… Admin Server**
   - REST API for cache management
   - Health checks and metrics
   - Manual invalidation and refresh
   - Operational visibility

   ```go
   vexilla.WithAdminServer(vexilla.AdminConfig{
       Port: 19000,
   })
   ```

3. **âœ… HTTP Middleware**
   - Automatic request context injection
   - Seamless integration with `http.Handler`
   - Eliminates boilerplate code

   ```go
   handler := client.HTTPMiddleware(myHandler)
   ```

4. **âœ… Deterministic Rollout Pattern**
   - Pre-computed bucket-based evaluation
   - 100% local evaluation for rollouts
   - Zero HTTP overhead
   - See [Deterministic Rollout Pattern](#deterministic-rollout-pattern) section

### ğŸ”œ Future Enhancements

1. **Distributed Cache** (Redis/Memcached)
   - Shared cache across instances
   - Strict consistency option
   - Cache warming strategies

2. **Batch Evaluation API**
   ```go
   results := cache.EvaluateMany(ctx, []string{"flag1", "flag2", "flag3"}, evalCtx)
   ```

3. **Predictive Pre-fetching**
   - Learn access patterns
   - Pre-warm cache for likely evaluations
   - ML-based prediction

4. **Compression**
   - Compress flag data on disk
   - Reduce memory footprint
   - Optional ZSTD compression

5. **gRPC Support**
   - Lower latency than HTTP
   - Better streaming for updates
   - Bi-directional communication

6. **Advanced Filtering**
   - Custom filter functions
   - Regex-based tag matching
   - Time-based filtering (active hours)

7. **Enhanced Telemetry**
   - Per-flag metrics
   - Evaluation latency percentiles
   - Cache efficiency scoring

---

## Testing Strategy

### Unit Tests
- All packages have `_test.go` files
- Mock implementations for dependencies
- Table-driven tests
- Target: >80% coverage

### Integration Tests
- Test against real Flagr instance
- Docker-based test environment
- End-to-end evaluation flows

### Benchmarks
- Performance regression detection
- Memory allocation tracking
- Throughput measurements

### Load Tests
- Concurrent evaluation stress tests
- Cache eviction behavior under load
- Circuit breaker trigger testing

---

## Conclusion

Vexilla provides a production-grade caching layer for Flagr that:

1. **Dramatically improves performance** (50-200x) for deterministic flags
2. **Reduces infrastructure load** (0-95%) on Flagr servers
3. **Maintains full compatibility** with Flagr's feature set
4. **Provides intelligent filtering** for resource optimization
5. **Offers enterprise features** (observability, resilience, persistence)
6. **Enables real-time updates** via webhook invalidation
7. **Simplifies operations** with admin API and HTTP middleware
8. **Supports deterministic rollouts** for offline-first evaluation

The architecture balances performance, reliability, and maintainability while providing clear extension points for future enhancements.

---

**Built with â¤ï¸ for high-performance feature flagging** ğŸ´
